{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlfUfMdnhyIFFJubCHgwSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnYCLam/MachineLearning/blob/main/TensorFlow_and_PyTorch_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST Dataset Demo - Tensorflow"
      ],
      "metadata": {
        "id": "u0mnBxNCisU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-r-EGGtikIc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "tRWHc6cR8rBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "hgXs8deLsnRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = x_train[0]\n",
        "label = y_train[0]"
      ],
      "metadata": {
        "id": "b9tRYeZ7-ir7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.imshow(image.squeeze(), cmap = \"gray\")\n",
        "ax.set_title(f'Class Label: {label}')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "7BciFiU0-hi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "zFDVVc1-RjP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "output_shape = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "rLEJmUwbeDOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Dense, Input"
      ],
      "metadata": {
        "id": "LaPGxOnOBMDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simpleModel(input_shape, output_shape, act_units, drop_outs = None, act_fcn = 'relu'):\n",
        "\n",
        "    model_sequence = [Input(shape = input_shape), Flatten()]\n",
        "    for i in range(len(act_units)):\n",
        "        model_sequence.append(Dense(act_units[i], activation = act_fcn))\n",
        "        if type(drop_outs) == list:\n",
        "            model_sequence.append(Dropout(drop_outs[i]))\n",
        "    model_sequence.append(Dense(output_shape, activation = 'softmax'))\n",
        "    model = tf.keras.models.Sequential(model_sequence)\n",
        "    return model"
      ],
      "metadata": {
        "id": "VZF8jZyvZglM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = simpleModel(image.shape, output_shape, [128], [0.2])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wG0hZZYBdzR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# difference between sparse categorical crossentropy and categorical crossentropy\n",
        "# categorical crossentropy: the labels are in one-hot encoding, e.g. [0, 0, 0, 1]\n",
        "# sparse categorical crossentropy: the labels are single values. e.g. 3\n",
        "# https://stackoverflow.com/questions/58565394/what-is-the-difference-between-sparse-categorical-crossentropy-and-categorical-c\n",
        "def model_train(model, x_train, y_train, x_test, y_test, loss, optimizer = 'adam', metrics = ['accuracy'], epochs = 10):\n",
        "\n",
        "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "    result = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = epochs)\n",
        "    return result"
      ],
      "metadata": {
        "id": "S4D32zlhSCh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model_train(model, x_train, y_train, x_test, y_test, 'sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "tMRz26RHkpTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if we use categorical crossentropy, we have to convert the labels into one-hot encoding first\n",
        "\n",
        "y_train = tf.one_hot(y_train, depth = 10)\n",
        "y_test = tf.one_hot(y_test, depth = 10)\n",
        "\n",
        "model_2 = simpleModel(image.shape, output_shape, [128], [0.2])\n",
        "result_2 = model_train(model_2, x_train, y_train, x_test, y_test, 'categorical_crossentropy')"
      ],
      "metadata": {
        "id": "PcCxj7cYXzk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize = (8, 4), sharey = True)\n",
        "\n",
        "ax[0].plot(result.history['accuracy'], label = 'acc')\n",
        "ax[0].plot(result.history['val_accuracy'], label = 'val_acc')\n",
        "ax[0].set_title('Model 1 Accuracy')\n",
        "ax[0].legend()\n",
        "ax[1].plot(result_2.history['accuracy'], label = 'acc')\n",
        "ax[1].plot(result_2.history['val_accuracy'], label = 'val_acc')\n",
        "ax[1].set_title('Model 2 Accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mytvl8UEl5rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize = (8, 4), sharey = True)\n",
        "\n",
        "ax[0].plot(result.history['loss'], label = 'loss')\n",
        "ax[0].plot(result.history['val_loss'], label = 'val_loss')\n",
        "ax[0].set_title('Model 1 Loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(result_2.history['loss'], label = 'loss')\n",
        "ax[1].plot(result_2.history['val_loss'], label = 'val_loss')\n",
        "ax[1].set_title('Model 2 Loss')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KQBrOcc2ohUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST Dataset Demo - PyTorch"
      ],
      "metadata": {
        "id": "hHK3UZCp4cOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KctdrEi14jqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "wKft3mpXSxxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "metadata": {
        "id": "2yHiFit-5Yxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.MNIST(\"data\", train = True, download = True, transform = ToTensor())\n",
        "test_data = torchvision.datasets.MNIST(\"data\", train = False, download = True, transform = ToTensor())\n",
        "\n",
        "print(f'No. of training data: {len(train_data)} | No. of test data: {len(test_data)}')"
      ],
      "metadata": {
        "id": "mP0uWHeH7rp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image.shape, label"
      ],
      "metadata": {
        "id": "2VmcwxsG_VaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "6JjqlMqyDgXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.imshow(image.squeeze(), cmap = \"gray\")\n",
        "ax.set_title(f'Class Label: {label}')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yVTLXrtwFM6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class simplePyTorchModel(nn.Module):\n",
        "    def __init__(self, input_shape, output_shape, act_units, drop_outs = None, act_fcn = 'relu'):\n",
        "        super().__init__()\n",
        "        model_sequence = [nn.Flatten()]\n",
        "\n",
        "        act_units.insert(0, input_shape)\n",
        "\n",
        "        for i in range(len(act_units) - 1):\n",
        "\n",
        "            model_sequence.append(nn.Linear(act_units[i], act_units[i + 1]))\n",
        "\n",
        "            if act_fcn == 'relu':\n",
        "                model_sequence.append(nn.ReLU())\n",
        "            elif act_fcn == 'tanh':\n",
        "                model_sequence.append(nn.Tanh())\n",
        "            elif act_fcn == 'sigmoid':\n",
        "                model_sequence.append(nn.Sigmoid())\n",
        "            else:\n",
        "                raise Exception(\"Unsupported Activation Function\")\n",
        "\n",
        "            if type(drop_outs) == list:\n",
        "                model_sequence.append(nn.Dropout(drop_outs[i]))\n",
        "\n",
        "        model_sequence.append(nn.Linear(act_units[-1], output_shape))\n",
        "\n",
        "        self.block = nn.Sequential(*model_sequence)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ],
      "metadata": {
        "id": "hWjfSsuWFdt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = simplePyTorchModel(image.shape[1] * image.shape[2], len(class_names), [128], [0.2])\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zAZmrhiyQXXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size = (50000, 1, 28, 28))"
      ],
      "metadata": {
        "id": "mcBTiHR0S-42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def dataloader(train_data, test_data, batch_size):\n",
        "\n",
        "    train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "_06AQhwqft1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader = dataloader(train_data, test_data, 32)\n",
        "\n",
        "print(f'Number of batches in train data: {len(train_dataloader)}')\n",
        "print(f'Number of batches in test data: {len(test_dataloader)}')"
      ],
      "metadata": {
        "id": "F7WP6LHpVfGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "acc_fcn = torchmetrics.Accuracy(task = 'multiclass', num_classes = len(class_names)).to(device)\n",
        "loss_fcn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "wjaa3DIXXiiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, device, loss_fcn, acc_fcn, optimizer, train_dataloader):\n",
        "\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X_train, y_train) in enumerate(train_dataloader):\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "\n",
        "        y_train_pred = model(X_train)\n",
        "\n",
        "        batch_loss = loss_fcn(y_train_pred, y_train)\n",
        "        train_loss += batch_loss\n",
        "        train_acc += acc_fcn(y_train_pred, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f'Read through {batch * len(X_train)}/{len(train_dataloader.dataset)} samples')\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_acc /= len(train_dataloader)\n",
        "\n",
        "    return train_loss, train_acc\n"
      ],
      "metadata": {
        "id": "OGEFhxpdfTrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, device, loss_fcn, acc_fcn, optimizer, test_dataloader):\n",
        "\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X_test, y_test in test_dataloader:\n",
        "\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "\n",
        "            y_test_pred = model(X_test)\n",
        "\n",
        "            test_loss += loss_fcn(y_test_pred, y_test)\n",
        "            test_acc += acc_fcn(y_test_pred, y_test)\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "N0MeFAFFoe17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def model_training(model, device, loss_fcn, acc_fcn, optimizer, train_dataloader, test_dataloader, epochs = 10):\n",
        "\n",
        "    results = {'train_acc': [], 'train_loss': [], 'test_acc': [], 'test_loss': []}\n",
        "\n",
        "    total_start_time = timer()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        epoch_start_time = timer()\n",
        "        print(f'Epoch: {epoch + 1}')\n",
        "\n",
        "        train_loss, train_acc = train_step(model, device, loss_fcn, acc_fcn, optimizer, train_dataloader)\n",
        "\n",
        "        test_loss, test_acc = test_step(model, device, loss_fcn, acc_fcn, optimizer, test_dataloader)\n",
        "\n",
        "        results['train_loss'].append(train_loss)\n",
        "        results['train_acc'].append(train_acc)\n",
        "        results['test_loss'].append(test_loss)\n",
        "        results['test_acc'].append(test_acc)\n",
        "\n",
        "        epoch_end_time = timer()\n",
        "\n",
        "        print(f\"\\nEpoch Train Time: {epoch_end_time - epoch_start_time:.4f}\")\n",
        "        print(f\"Train Accuracy: {train_acc:.4f} | Train Loss: {train_loss:.4f} | Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f} \\n\")\n",
        "\n",
        "    total_end_time = timer()\n",
        "    print(f\"Total Time: {total_end_time - total_start_time:.4f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OBoy3Ya-qRtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_training(model, device, loss_fcn, acc_fcn, optimizer, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "id": "_33vS_I2ruO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(results['train_acc'], label = 'train_acc')\n",
        "ax.plot(results['test_acc'], label = 'test_acc')\n",
        "ax.set_title('Model Accuracy')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDdKs_DRzuNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "results['train_loss'] = [loss.detach().numpy() for loss in results['train_loss']]\n",
        "ax.plot(results['train_loss'], label = 'train_loss')\n",
        "ax.plot(results['test_loss'], label = 'test_loss')\n",
        "ax.set_title('Model Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "igkwnqaWA81N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}